# 混合文本剪贴板分词逻辑构思

## 单模式

- 智能分析(默认启用)
- 中文分析
- 英文分析
- 代码分析
- 乱码分析
- 整句分析
- 完整拆散
  - 使用标点和空格换行分隔,将中文英文分开,再将

## 多模式结合

## 资料

> [!文献]- [自然语言处理入门（4）——中文分词原理及分词工具介绍自然语言处理入门（4）——中文分词原理及分词工具介绍]()
>
> - 基于字符串匹配
>   - 正向最大匹配法（从左到右的方向）；
>   - 逆向最大匹配法（从右到左的方向）；
>   - 最小切分（每一句中切出的词数最小）；
>   - 双向最大匹配（进行从左到右、从右到左两次扫描）
> - 基于理解
> - 基于统计
> - 中文分词项目
>   - [jieba](https://github.com/fxsjy/jieba) - Python - 较多
>   - [SnowNLP](https://github.com/isnowfy/snownlp) - Python
>   - [THULAC](https://github.com/thunlp/THULAC) - Python/C++
>   - [NLPIR](https://github.com/NLPIR-team/NLPIR) - C/C++
>   - [HanLP](https://github.com/hankcs/HanLP) - Python/Java - Star最多
>   - [Jcseg](https://github.com/lionsoul2014/jcseg) - Java
>   - [sego](https://github.com/huichen/sego) - Go
>   - [FoolNLTK](https://github.com/rockyzhengwu/FoolNLTK) - Python - 最准
>   - [Ansj](https://github.com/NLPchina/ansj_seg) - Java
>   - [pkuseg](https://github.com/lancopku/pkuseg-python) - Python
>
> [Other List ](https://cloud.tencent.com/developer/article/1373033)

> [!文献]- [大模型基础 | 词典分词](https://zhuanlan.zhihu.com/p/1937472781899002624) ? For RAG
>
> `OOC` : Out Of Vocabulary, 中文可以翻译为"溢出词表的词"或"未登录词"，指的是在自然语言处理(NLP)系统中，出现在输入文本中但不在系统预设词汇表(vocabulary)中的词语。
>
> 设计最小分词单位: 从分词粒度来看，主要包括三种类型：Word、Subword和Char
>
> Transformer分词 : 子词分词器（Subword Tokenizer）被广泛应用于基于Transformer的语言模型中，包括BPE分词、WordPiece分词和Unigram分词三种常见方法。

## AskAI

`NLP` : 自然语言处理
跳词: readline(固定2,的地得3,专名不定)

### 项目实现

我的需求 快+超轻量+JavaScript

- 词典匹配
- 统计模型
- 深度学习

### 互联网厂输入法

| 输入法   | 核心方法                           | 特色优化                 |
| -------- | ---------------------------------- | ------------------------ |
| 搜狗     | 词典 + CRF+Transformer 小模型      | 词库动态更新，场景化适配 |
| 百度     | 专有词典 + 双向最大匹配 + 深度学习 | 最短路径消歧，一键分词   |
| 讯飞     | HMM+CRF+BERT                       | AI 分类，交互式拆词      |
| 微信     | 双向最大匹配 + 轻量 Transformer    | 生态语料适配，离线优先   |
| 微软拼音 | 词典 + 统计模型 + BiLSTM+CRF       | Office 词库，跨端同步    |
| 谷歌拼音 | 轻量 Transformer+n‑gram            | 多语言适配，本地高效     |

**炸词**
|软件/功能|核心定位|分词引擎|关键技术|交互特点|适用场景|
|:-|:-|:-|:-|:-|:-|
|锤子BigBang|系统级文本炸词|三角兽分词+自维护词典|OCR识别图片文字；正向最大匹配+词典；二次拆分（菜刀按钮）|长按触发；指纹定位；气泡式词块；可拖动排序|任意界面文本/图片，支持搜索、分享、编辑|
|搜狗输入法|剪贴板/候选词炸词|搜狗自研分词器（词典+N-Gram）|Trie树前缀匹配；动态词频；上下文消歧|剪贴板内容一键炸词；候选词长按炸开；支持自定义词库|输入场景、剪贴板快速选词、文本重组|
|讯飞输入法|输入+剪贴板炸词|讯飞星火NLP+统计模型|混合分词（规则+统计）；HMM处理歧义；用户习惯学习|候选词展开；长文本智能分句；语音转写后分词|语音输入后整理；长句快速拆分；跨APP文本复用|
|百度输入法|智能分词+炸词|百度文心分词模型|深度学习分词；实体识别；实时词库更新|分词结果可编辑；支持多粒度拆分；OCR炸图|复杂文本处理；专有名词识别；多场景文本提取|
|Rime（小狼毫）|开源定制化分词|自定义词典+Rime分词模块|双向最大匹配；用户词库优先；可配置分词规则|基于输入串动态分词；候选词可拆分为单字|桌面端高效输入；精准分词需求；高度定制化场景|

### 企业级

[中文分词详解：从词典匹配到深度学习方法](https://allenwind.github.io/blog/8269/)

`word tokenization` : 分词

`CWS` : chinese word segment 中文分词

**作用:**

1. 缓解一字多义问题;
2. 让模型从word-level学习，降低模型学习难度，可以理解成是先验知识的引入;
3. 便于引入预训练模型的信息，如引入word2vec的词向量

**不足:**

- 不规范(《信息处理用现代词汉语分词规范》参考不足)
- 性能
- 污染
- 歧义(交集型歧义;组合型歧义;真歧义)
- 更新(未登录词,新生词汇,网络词汇)
- 跨端

**混合模型在特定文本中的应用**
在特定领域的文本，如法律文档、技术手册等，经常会出现大量的专业术语。混合模型通过引入专业词典，可以大幅提升这些术语的识别率。例如，构建一个以生物医学词典为基础的混合分词模型，可以有效提高医学文献的分词准确性。具体操作步骤如下：

1. 词典准备 ：收集并整理生物医学领域的专业词典，准备成适合模型引用的格式。
2. 语料预处理 ：对生物医学文本进行预处理，使用专业词典进行词边界标注。
3. 模型训练 ：用预处理后的文本作为训练数据，结合生物医学词典，训练CRF模型。
4. 分词实现 ：对新的生物医学文本进行分词处理，使用训练好的模型和词典进行匹配和识别。

_混合模型 VS 统计模型_
准确度
召回率
$F_1$分数

_词典匹配的分词方法根据文本的扫描方向可以分为：正向和逆向；根据词的匹配策略可以分为：最长词优先和最短词优先。具体地，常见的基于词典匹配的分词方法：_

完全切分匹配（扫描句子，只要组成词就切分）(准确说更像查词)
正向最长匹配
逆向最长匹配
正向最小匹配（汉语中通常是成词出现，因此较少用）
逆向最小匹配
双向最长匹配（正向最长匹配+逆向最长匹配，并使用最少切分策略即选择词数更少的结果，或者其他策略）

_词典分词结合==词频==信息_

`DAG` : 有向无环

最短路径分词算法

最大概率组合

**前缀词典与哈希索引、Trie树和AC自动机**

POS

序列标注思路 NER allenwind/tensorflow-crf

_逐字标注的分词方法：_

1. HMM（viterbi decode）
2. MEMM（viterbi decode）
3. Linear + CRF
4. MLP + 逐位置分类模型（softmax）
5. 深度模型（CNN、RNN、LSTM） + CRF

HMM & MEMM 可见[参考](https://allenwind.github.io/blog/7681/):概率图模型系列（3）：隐马尔可夫模型（HMM）

MLP + 逐位置softmax (如分类任务)

深度模型 + CRF

**评估方法**

没有测量就是没有科学，中文分词也不例外，最常见的评估指标是prf和分类问题类似：

precision
recall
对OOV的召回
$F_1$

基于统计模型(亦为无字典分词)
一、基于N-gram语言模型的分词方法
二、基于HMM（隐马尔科夫模型）的分词方法
三、基于CRF（条件随机场）的分词方法
四、CRF VS HMM

### More else

[词向量系列（1）：VSM与词袋模型](https://allenwind.github.io/blog/8233/)

向量化
count-in-parallel
Words cloud

TextRank:文本的基于图的排序算法。

《统计自然语言处理（第2版）》
